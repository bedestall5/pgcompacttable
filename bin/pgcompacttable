#!/usr/bin/perl

use strict;
use warnings;

use Time::HiRes qw/time sleep/;
use POSIX;
use Getopt::Long;
use DBI;

use Data::Dumper;

my $option_hash;

select(STDOUT);

our $_log = select();
our $_log_level;
our $_dbh;

use constant MINIMAL_COMPACT_PAGES => 10;
use constant MINIMAL_COMPACT_PERCENT => 20;
use constant PAGES_PER_ROUND_DIVISOR => 1000;
use constant MAX_PAGES_PER_ROUND => 5;
use constant PAGES_BEFORE_VACUUM_LOWER_DIVISOR => 16;
use constant PAGES_BEFORE_VACUUM_LOWER_THRESHOLD => 1000;
use constant PAGES_BEFORE_VACUUM_UPPER_DIVISOR => 50;
use constant PROGRESS_REPORT_PERIOD => 60;
use constant LOCKED_ALTER_TIMEOUT => 1000;
use constant LOCKED_ALTER_COUNT => 100;
# Settings & defaults

our %log_levels = (
  'quiet' => 0,
  'notice' => 1,
  'verbose' => 2
);

my $help;
my $man;

my $db_host = 'localhost';
my $db_port = 5432;
my $db_user = $ENV{LOGNAME} || $ENV{USER} || getpwuid($<);
my $db_passwd = '';

my $db_name = $ENV{LOGNAME} || $ENV{USER} || getpwuid($<);
my $schema_name = 'public';
my $table_name;

my $verbosity = 'notice';
my $force;
my $delay_ratio = 0;
my $routine_vacuum;
my $no_reindex;
my $print_reindex_queries = 0;
my $max_retry_count = 10;

my $all_db;

my $exclude_schema;
my $exclude_table;
my %excluded_schemas;
my %excluded_tables;

GetOptions(
            #help & man
            'help|?' => \$help,
            'm|man' => \$man,

            #database connection parameters
            'h|host=s' => \$db_host,
            'p|port=i' => \$db_port,
            'U|user=s' => \$db_user,
            'W|password=s' => \$db_passwd,
            'd=s' => \$db_name,
            'n|schema=s' => \$schema_name,
            't|table=s' => \$table_name,
            'v|verbosity=s' => \$verbosity,
            'f|force' => \$force,
            'no-reindex' => \$no_reindex,
            'print-reindex-queries' => \$print_reindex_queries,
            'max-retry-count=i' => \$max_retry_count,
            'delay-ratio=i' => \$delay_ratio,
            'routine-vacuum' => \$routine_vacuum,
            'all' => \$all_db,
            'N|exclude-schema=s' => \$exclude_schema,
            'T|exclude-table=s' => \$exclude_table,
          );

$_log_level = $log_levels{$verbosity} || 1;

our $_current_db_name;
our $_current_schema_name;
our $_current_table_name;

sub set_current_db_name {
  $_current_db_name = shift;
}

sub set_current_schema_name_table_name {
  $_current_schema_name = shift;
  $_current_table_name = shift;
}

sub unset_current_db_name {
  undef $_current_db_name;
}

sub unset_current_schema_name_table_name {
  undef $_current_schema_name;
  undef$_current_table_name;
}

sub logger {
  my $level = shift;
  my $message = shift;
  my @message_args = @_;

  no strict;
  print $_log sprintf("[%s](%s) $message\n", (scalar(localtime), (($_current_db_name ? "$_current_db_name:" : "").(($_current_schema_name && $_current_table_name) ? "$_current_schema_name.$_current_table_name" : "")), @message_args)) if (($log_levels{$level} || 1) >= $_log_level);
  use strict;
}

sub help {
  logger('quiet', "This is help");
  return 1;
}

sub man {
  logger('quiet', "This is man");
  return 1;
}

sub nice_size
{
  my $size = shift;
  my @sizes = qw/B KB MB GB TB PB/;

  my $i = 0;

  while ($size > 1024) {
    $size = $size / 1024;
    $i++;
  }
  return sprintf("%.3f$sizes[$i]", $size);
}

#DB procedures

sub _dbh {
  return $_dbh;
}

sub db_connect {
  my $db_name = shift;
  my $db_host = shift;
  my $db_port = shift;
  my $db_user = shift;
  my $db_password = shift;

  logger('quiet', "Connecting to database");

  $_dbh = DBI->connect("DBI:Pg:dbname=$db_name;host=$db_host;port=$db_port", $db_user, $db_password,{RaiseError => 0, PrintError => 0, AutoCommit => 1});
  
  if($DBI::err) { 
    logger('quiet', "Cannot connect DBI:Pg:dbname=%s;host=%s;port=%s user=%s,passwd=...: %s", $db_name, $db_host, $db_port, $db_user, $DBI::errstr); 
    return undef;
  }

  return $_dbh;
}

sub db_disconnect {
  my $db_name = shift;
  logger('quiet', "Disconnecting from database");
  _dbh->disconnect;
}

sub get_databases {
  my $sth = _dbh->prepare("
SELECT datname FROM pg_catalog.pg_database
WHERE
    datname NOT IN ('template0')
ORDER BY pg_catalog.pg_database_size(datname), datname
  ");
  $sth->execute;
  
  if ($DBI::err) {
    logger('quiet', "SQL Error: %s", $DBI::errstr);
    return undef;
  }

  my @result;
  while(my ($db_name) = $sth->fetchrow_array) {
    push @result, $db_name;
  }

  return \@result || [];
}

sub get_database_tables {
  my $sth = _dbh->prepare("
SELECT schemaname, tablename FROM pg_catalog.pg_tables
WHERE
    NOT (schemaname = 'pg_catalog' AND tablename = 'pg_index') AND
    schemaname !~ 'pg_(temp|toast|catalog).*' AND
    NOT schemaname = 'information_schema'
ORDER BY
    pg_catalog.pg_relation_size(
        quote_ident(schemaname) || '.' || quote_ident(tablename)),
    schemaname, tablename 
  ");
  
  if ($DBI::err) {
    logger('quiet', "SQL Error: %s", $DBI::errstr);
    return undef;
  }

  $sth->execute;
  my @result;
  while(my $ident = $sth->fetchrow_hashref) {
    push @result, $ident;
  }
  return \@result || [];
}

sub get_pgstattuple_schema_name {
  my $sth = _dbh->prepare("
SELECT nspname FROM pg_catalog.pg_proc
JOIN pg_catalog.pg_namespace AS n ON pronamespace = n.oid
WHERE proname = 'pgstattuple' LIMIT 1
");
  $sth->execute;

  if ($DBI::err) {
    logger('quiet', "SQL Error: %s", $DBI::errstr);
    return undef;
  }

  my ($pgstattuple_schema_name) = $sth->fetchrow_array; 
  return $pgstattuple_schema_name;
}

sub get_size_stats {
  my $schema_name = shift;
  my $table_name = shift;
  
  my $ident_name = $schema_name.".".$table_name;
  my $sth = _dbh->prepare("
SELECT
    size,
    total_size,
    ceil(size::real / bs) AS page_count,
    ceil(total_size::real / bs) AS total_page_count
FROM (
    SELECT
        current_setting('block_size')::integer AS bs,
        pg_catalog.pg_relation_size(quote_ident(?)||'.'||quote_ident(?)) AS size,
        pg_catalog.pg_total_relation_size(quote_ident(?)||'.'||quote_ident(?)) AS total_size
) AS sq
");

  $sth->execute($schema_name, $table_name, $schema_name, $table_name);

  if ($DBI::err) {
    logger('quiet', "SQL Error: %s", $DBI::errstr);
    return undef;
  }

  my $result = $sth->fetchrow_hashref;
  
  if (! $result || ref $result ne 'HASH') {
    logger('quiet',"Cannot get size statistics");
  }
  
  return $result;
}

sub get_bloat_stats {
  my $schema_name = shift;
  my $table_name = shift;

  my $ident_name = $schema_name.".".$table_name;
 
  my $pgstattuple_schema_name = get_pgstattuple_schema_name;
 
  return undef unless($pgstattuple_schema_name);

  my $sth = _dbh->prepare("SELECT
    ceil((size - free_space) * 100 / fillfactor / bs) AS effective_page_count,
    round(
        (100 * (1 - (100 - free_percent) / fillfactor))::numeric, 2
    ) AS free_percent,
    ceil(size - (size - free_space) * 100 / fillfactor) AS free_space
    FROM (
    SELECT
        current_setting('block_size')::integer AS bs,
        pg_catalog.pg_relation_size(pg_catalog.pg_class.oid) AS size,
        coalesce(
            (
                SELECT (
                    regexp_matches(
                        reloptions::text, E'.*fillfactor=(\\\\d+).*'))[1]),
            '100')::real AS fillfactor,
        pgst.*
    FROM pg_catalog.pg_class
    CROSS JOIN
        $pgstattuple_schema_name.pgstattuple(
            (quote_ident(?) || '.' || quote_ident(?))) AS pgst
    WHERE pg_catalog.pg_class.oid = (quote_ident(?) || '.' || quote_ident(?))::regclass
    ) AS sq");
  $sth->execute($schema_name, $table_name, $schema_name, $table_name);

  if ($DBI::err) {
    logger('quiet', "SQL Error: %s", $DBI::errstr);
    return undef;
  }

  my $result = $sth->fetchrow_hashref;
 
  return $result;
}

sub get_update_column {
  my $schema_name = shift;
  my $table_name = shift;

  my $sth = _dbh->prepare("SELECT quote_ident(attname)
    FROM pg_catalog.pg_attribute
    WHERE
    attnum > 0 AND -- neither system
    NOT attisdropped AND -- nor dropped
    attrelid = (quote_ident(?) || '.' || quote_ident(?))::regclass
    ORDER BY
    -- Variable legth attributes have lower priority because of the chance
    -- of being toasted
    (attlen = -1),
    -- Preferably not indexed attributes
    (
        attnum::text IN (
            SELECT regexp_split_to_table(indkey::text, ' ')
            FROM pg_catalog.pg_index
            WHERE indrelid = (quote_ident(?) || '.' || quote_ident(?))::regclass)),
    -- Preferably smaller attributes
    attlen,
    attnum
    LIMIT 1;");

  $sth->execute($schema_name, $table_name, $schema_name, $table_name);

  if ($DBI::err) {
    logger('quiet', "SQL Error: %s", $DBI::errstr);
    return undef;
  }

  my ($result) = $sth->fetchrow_array;  
  return $result;
}

sub get_pages_per_round {
  my $page_count = shift;
  my $to_page = shift;

  my $real_pages_per_round = $page_count / PAGES_PER_ROUND_DIVISOR > 1 ? $page_count / PAGES_PER_ROUND_DIVISOR : 1; 
  my $pages_per_round = $real_pages_per_round < MAX_PAGES_PER_ROUND ? $real_pages_per_round : MAX_PAGES_PER_ROUND;
  my $result = ceil($pages_per_round) < $to_page ?  ceil($pages_per_round) : $to_page; 

  return $result;
}

sub get_pages_before_vacuum {
  my $page_count = shift;
  my $expected_page_count = shift;

  my $pages = $page_count / PAGES_BEFORE_VACUUM_LOWER_DIVISOR < PAGES_BEFORE_VACUUM_LOWER_THRESHOLD ? $page_count / PAGES_BEFORE_VACUUM_LOWER_DIVISOR : $page_count / PAGES_BEFORE_VACUUM_LOWER_THRESHOLD;
  my $result = $pages > $expected_page_count / PAGES_BEFORE_VACUUM_UPPER_DIVISOR ? $pages : $expected_page_count / PAGES_BEFORE_VACUUM_UPPER_DIVISOR;

  return ceil($result);
}

sub get_max_tupples_per_page {
  my $schema_name = shift;
  my $table_name = shift;

  my $ident_name = $schema_name.".".$table_name;

  my $sth = _dbh->prepare("
          SELECT ceil(current_setting('block_size')::real / sum(attlen))
          FROM pg_catalog.pg_attribute
          WHERE
              attrelid = '$ident_name'::regclass AND
              attnum < 0;
              ");
  $sth->execute;

  if ($DBI::err) {
    logger('quiet', "SQL Error: %s", $DBI::errstr);
    return undef;
  }

  my ($result) = $sth->fetchrow_array; 

  logger('quiet', 'Can not get max tupples per page.') unless(defined $result);

  return $result;
}

sub has_triggers {
  my $schema_name = shift;
  my $table_name = shift;

  my $ident_name = $schema_name.".".$table_name;

  my $sth = _dbh->prepare("SELECT count(1) FROM pg_catalog.pg_trigger
  WHERE
      tgrelid = '$ident_name'::regclass AND
      tgenabled IN ('A', 'R') AND
      (tgtype & 16)::boolean");
  $sth->execute;

  if ($DBI::err) {
    logger('quiet', "SQL Error: %s", $DBI::errstr);
    return undef;
  }

  my ($result) = $sth->fetchrow_array;

  return $result;
}

sub try_advisory_lock {
  my $schema_name = shift;
  my $table_name = shift;
 
  my $sth = _dbh->prepare("
  SELECT pg_try_advisory_lock(
    'pg_catalog.pg_class'::regclass::integer,
    (quote_ident(?)||'.'||quote_ident(?))::regclass::integer)::integer;
    ");
  $sth->execute($schema_name, $table_name);

  if ($DBI::err) {
    logger('quiet', "SQL Error: %s", $DBI::errstr);
    return undef;
  }

  my ($lock) = $sth->fetchrow_array;

  logger('notice', "Skipping processing: another instance is working with table %s.%s", $schema_name, $table_name) unless ($lock); 
  
  return $lock;
}

sub vacuum {
  my $schema_name = shift;
  my $table_name = shift;
  my $analyze = shift; 
  

  #my $sth = _dbh->do('VACUUM '.($analyze ? 'ANALYZE ' : '')."(quote_ident(?)||'.'||quote_ident(?)", undef, $schema_name, $table_name);
  my $sth = _dbh->do('VACUUM '.($analyze ? 'ANALYZE ' : '')."$schema_name.$table_name");
  
  if ($DBI::err) {
    logger('quiet', "SQL Error: %s", $DBI::errstr);
    return undef;
  }

  return;
}

sub analyze {
  my $schema_name = shift;
  my $table_name = shift;

  #my $sth = $_dbh->do('ANALYZE (quote_ident(?)||'.'||quote_ident(?)', undef, $schema_name, $table_name);
  my $sth = $_dbh->do("ANALYZE $schema_name.$table_name");

  if ($DBI::err) {
    logger('quiet', "SQL Error: %s", $DBI::errstr);
    return undef;
  }

  return;
}

sub set_session_replication_role {
  my $sth = $_dbh->do('set session_replication_role to replica;');

  if ($DBI::err) {
    logger('quiet', "SQL Error: %s", $DBI::errstr);
    return undef;
  }

  return;
}

sub create_clean_pages_function {
  
  _dbh->do("
CREATE OR REPLACE FUNCTION public.pgcompact_clean_pages_$$(
    i_table_ident text,
    i_column_ident text,
    i_to_page integer,
    i_page_offset integer,
    i_max_tupples_per_page integer)
RETURNS integer
LANGUAGE plpgsql AS \$\$
DECLARE
    _from_page integer := i_to_page - i_page_offset + 1;
    _min_ctid tid;
    _max_ctid tid;
    _ctid_list tid[];
    _next_ctid_list tid[];
    _ctid tid;
    _loop integer;
    _result_page integer;
    _update_query text :=
        'UPDATE ONLY ' || i_table_ident ||
        ' SET ' || i_column_ident || ' = ' || i_column_ident ||
        ' WHERE ctid = ANY(\$1) RETURNING ctid';
BEGIN
    -- Check page argument values
    IF NOT (
        i_page_offset IS NOT NULL AND i_page_offset >= 1 AND
        i_to_page IS NOT NULL AND i_to_page >= 1 AND
        i_to_page >= i_page_offset)
    THEN
        RAISE EXCEPTION 'Wrong page arguments specified.';
    END IF;

    -- Check that session_replication_role is set to replica to
    -- prevent triggers firing
    IF NOT (
        SELECT setting = 'replica'
        FROM pg_catalog.pg_settings
        WHERE name = 'session_replication_role')
    THEN
        RAISE EXCEPTION 'The session_replication_role must be set to replica.';
    END IF;

    -- Define minimal and maximal ctid values of the range
    _min_ctid := (_from_page, 1)::text::tid;
    _max_ctid := (i_to_page, i_max_tupples_per_page)::text::tid;

    -- Build a list of possible ctid values of the range
    SELECT array_agg((pi, ti)::text::tid)
    INTO _ctid_list
    FROM generate_series(_from_page, i_to_page) AS pi
    CROSS JOIN generate_series(1, i_max_tupples_per_page) AS ti;

    <<_outer_loop>>
    FOR _loop IN 1..i_max_tupples_per_page LOOP
        _next_ctid_list := array[]::tid[];

        -- Update all the tuples in the range
        FOR _ctid IN EXECUTE _update_query USING _ctid_list
        LOOP
            IF _ctid > _max_ctid THEN
                _result_page := -1;
                EXIT _outer_loop;
            ELSIF _ctid >= _min_ctid THEN
                -- The tuple is still in the range, more updates are needed
                _next_ctid_list := _next_ctid_list || _ctid;
            END IF;
        END LOOP;

        _ctid_list := _next_ctid_list;

        -- Finish processing if there are no tupples in the range left
        IF coalesce(array_length(_ctid_list, 1), 0) = 0 THEN
            _result_page := _from_page - 1;
            EXIT _outer_loop;
        END IF;
    END LOOP;

    -- No result
    IF _loop = i_max_tupples_per_page AND _result_page IS NULL THEN
        RAISE EXCEPTION
            'Maximal loops count has been reached with no result.';
    END IF;

    RETURN _result_page;
END \$\$;
  ");

  if ($DBI::err) {
    logger('quiet', "SQL Error: %s", $DBI::errstr);
    return undef;
  }

  return 1;
}

sub drop_clean_pages_function {
  _dbh->do("
    DROP FUNCTION public.pgcompact_clean_pages_$$(text, text,integer, integer, integer);
    ");
  if ($DBI::err) {
    logger('quiet', "SQL Error: %s", $DBI::errstr);
    return undef;
  }

  return ;
}

sub clean_pages {
  my $schema_name = shift;
  my $table_name = shift;
  my $column_name = shift;
  my $to_page = shift;
  my $pages_per_round = shift;
  my $max_tupples_per_page = shift;

  my $ident_name = $schema_name.".".$table_name;
  my $sth = _dbh->prepare("
    SELECT public.pgcompact_clean_pages_$$(?,?,?,?,?)
  ");
  $sth->execute($ident_name, $column_name, $to_page,  $pages_per_round, $max_tupples_per_page);

  if ($DBI::err) {
    logger('quiet', "SQL Error: %s", $DBI::errstr);
    die $DBI::errstr;
  }
  
  my ($result) = $sth->fetchrow_array;

  return $result;
}

sub get_index_data_list {
  my $schema_name = shift;
  my $table_name = shift;

  my $sth = _dbh->prepare("
SELECT
    indexname, tablespace, indexdef,
    regexp_replace(indexdef, E'.* USING (\\\\w+) .*', E'\\\\1') AS indmethod,
    conname,
    CASE
        WHEN contype = 'p' THEN 'PRIMARY KEY'
        WHEN contype = 'u' THEN 'UNIQUE'
        ELSE NULL END AS contypedef,
    (
        SELECT
            bool_and(
                deptype IN ('n', 'a', 'i') AND
                NOT (refobjid = indexoid AND deptype = 'n') AND
                NOT (
                    objid = indexoid AND deptype = 'i' AND
                    (version < array[9,1] OR contype NOT IN ('p', 'u'))))
        FROM pg_catalog.pg_depend
        LEFT JOIN pg_catalog.pg_constraint ON
            pg_catalog.pg_constraint.oid = refobjid
        WHERE
            (objid = indexoid AND classid = pgclassid) OR
            (refobjid = indexoid AND refclassid = pgclassid)
    )::integer AS allowed,
    pg_catalog.pg_relation_size(indexoid)
FROM (
    SELECT
        indexname, tablespace, indexdef,
        (
            quote_ident(schemaname) || '.' ||
            quote_ident(indexname))::regclass AS indexoid,
        'pg_catalog.pg_class'::regclass AS pgclassid,
        string_to_array(
            regexp_replace(
                version(), E'.*PostgreSQL (\\\\d+\\\\.\\\\d+).*', E'\\\\1'),
            '.')::integer[] AS version
    FROM pg_catalog.pg_indexes
    WHERE
        schemaname = ? AND
        tablename = ?
) AS sq
LEFT JOIN pg_catalog.pg_constraint ON
    conindid = indexoid AND contype IN ('p', 'u')
ORDER BY 8
 ");
  
  $sth->execute($schema_name, $table_name);

  if ($DBI::err) {
    logger('quiet', "SQL Error: %s", $DBI::errstr);
    return undef;
  }

  my @result;
  while(my $result = $sth->fetchrow_hashref) {
    push @result, $result;
  }

  return \@result;
}

sub get_index_size_statistics {
  my $schema_name = shift;
  my $index_name = shift;

  my $sth = _dbh->prepare("
SELECT size, ceil(size / bs) AS page_count
FROM (
    SELECT
        pg_catalog.pg_relation_size((quote_ident(?) || '.' || quote_ident(?))::regclass) AS size,
        current_setting('block_size')::real AS bs
) AS sq
  ");

  $sth->execute($schema_name, $index_name);

  if ($DBI::err) {
    logger('quiet', "SQL Error: %s", $DBI::errstr);
    return undef;
  }

  my $result = $sth->fetchrow_hashref;
  
  return ($result && ref $result eq 'HASH' && $result->{size} && $result->{page_count} ? $result : undef);
}

sub get_reindex_query {
  my $index_data = shift;  

  my $sql = $index_data->{indexdef};
  $sql =~ s/INDEX (\S+)/INDEX CONCURRENTLY pgcompact_index_$$/;
  $sql =~ s/( WHERE .*|$)/ TABLESPACE $index_data->{tablespace}$1/ if (defined $index_data->{tablespace});

  return $sql;

}

sub get_alter_index_query {
  my $schema_name = shift;
  my $table_name = shift;
  my $index_data = shift;

  my $constraint_ident = $index_data->{conname} if ($index_data && ref $index_data eq 'HASH' && $index_data->{conname});

  return
    "BEGIN; SET LOCAL statement_timeout TO " . LOCKED_ALTER_TIMEOUT . "; 
    " . ($constraint_ident ?
      ("ALTER TABLE $schema_name.$table_name  DROP CONSTRAINT $constraint_ident;
ALTER TABLE $schema_name.$table_name ADD CONSTRAINT $constraint_ident $index_data->{contypedef} USING INDEX pgcompact_index_$$;") :
      ("DROP INDEX $schema_name.$index_data->{indexname}; ALTER INDEX $schema_name.pgcompact_index_$$ RENAME TO $index_data->{indexname};")
    )."END;";
}

sub get_straight_reindex_query {
  my $schema_name = shift;
  my $table_name = shift;
  my $index_data = shift;

  #return "REINDEX INDEX (quote_ident('$schema_name') || . || quote_ident('$index_data->{indexname}'));";
  return "REINDEX INDEX ('$schema_name.$index_data->{indexname}')";
}

sub get_index_bloat_stats {
  my $schema_name = shift;
  my $index_name = shift;

  my $pgstattuple_schema_name = get_pgstattuple_schema_name;

  return undef unless($pgstattuple_schema_name);  
  
  my $sth = _dbh->prepare("
SELECT
    CASE
        WHEN avg_leaf_density = 'NaN' THEN 0
        ELSE
            round(
                (100 * (1 - avg_leaf_density / fillfactor))::numeric, 2
            )
        END AS free_percent,
    CASE
        WHEN avg_leaf_density = 'NaN' THEN 0
        ELSE
            ceil(
                index_size * (1 - avg_leaf_density / fillfactor)
            )
        END AS free_space
FROM (
    SELECT
        coalesce(
            (
                SELECT (
                    regexp_matches(
                        reloptions::text, E'.*fillfactor=(\\\\d+).*'))[1]),
            '90')::real AS fillfactor,
        pgsi.*
    FROM pg_catalog.pg_class
    CROSS JOIN $pgstattuple_schema_name.pgstatindex(
        quote_ident(?) || '.' || quote_ident(?)) AS pgsi
    WHERE pg_catalog.pg_class.oid = (quote_ident(?) || '.' || quote_ident(?))::regclass
) AS oq
  ");
  $sth->execute($schema_name, $index_name, $schema_name, $index_name);

  if ($DBI::err) {
    logger('quiet', "SQL Error: %s", $DBI::errstr);
    return undef;
  }

  my $result = $sth->fetchrow_hashref;

  return ($result && ref $result eq 'HASH' && $result->{'free_percent'} && $result->{'free_space'}) ? $result : undef;
}

sub reindex {
  my $index_data = shift;

  _dbh->do(get_reindex_query($index_data));

  if ($DBI::err) {
    logger('quiet', "SQL Error: %s", $DBI::errstr);
    return undef;
  }

  return;
}

sub alter_index {
  my $schema_name = shift;
  my $table_name = shift;
  my $index_data = shift;
  
  foreach my $sql (split(/;/, get_alter_index_query($schema_name, $table_name, $index_data))) {
    next if ($sql =~ /^\s*$/);
    _dbh->do("$sql;");

    if ($DBI::err) {
      logger('quiet', "SQL Error: %s", $DBI::errstr);
      die;
      #return undef;
    }

  }
}

sub drop_temp_index {
  my $schema_name = shift;

  _dbh->do("SET LOCAL statement_timeout TO " . LOCKED_ALTER_TIMEOUT . ";"); 
  _dbh->do("DROP INDEX ?;", undef, "$schema_name.pgcompact_index_$$");

  if ($DBI::err) {
    logger('quiet', "SQL Error: %s", $DBI::errstr);
    return undef;
  }

  return;
}

#Process function

sub process {
  my $schema_name = shift;
  my $table_name = shift;
  my $attempt = shift;
  
  my $is_skipped;
  my $is_locked = try_advisory_lock($schema_name, $table_name) ? 0 : 1;

  if ($DBI::err) {
    logger('quiet', "Table handling interrupt.");
    return -1;
  }

  my $stats = get_size_stats($schema_name, $table_name); 

  if ($DBI::err) {
    logger('quiet', "Table handling interrupt.");
    return -1;
  }

  my $base_stats;
  $base_stats = {%$stats} unless ($base_stats);

  if (!$is_locked) {
    my $vacuum_time = time;
    vacuum($schema_name, $table_name);

    if ($DBI::err) {
      logger('quiet', "Table handling interrupt.");
      return -1;
    }    

    $vacuum_time = time - $vacuum_time;
    $stats = get_size_stats($schema_name, $table_name);
    if ($DBI::err) {
      logger('quiet', "Table handling interrupt."); 
      return -1;
    }

#  if ($stats->{page_count} > $stats->{page_count}) {
#    logger('quiet', "Vacuum initial: can not clean %d pages, %d' pages left, duration %d seconds.", ($stats->{page_count} - $stats->{page_count}), $stats->{page_count}, $vacuum_time);
#  } else {
      logger('quiet', "Vacuum initial: %d pages left, duration %.3f seconds.", ($stats->{page_count}||0), $vacuum_time);
#  }

    if($stats->{page_count} <= 1) {
      logger('quiet', "Skipping processing: empty or 1 page table.");
      $is_skipped = 1;
    }
  }

  my $bloat_stats;

  if (!$is_locked && !$is_skipped) {
    my $get_stat_time = time;
    $bloat_stats = get_bloat_stats($schema_name, $table_name);

    if ($DBI::err) {
      logger('quiet', "Table handling interrupt.");
      return -1;
    }
 
    $get_stat_time = time - $get_stat_time;
    if ($bloat_stats->{effective_page_count}) {
      logger('quiet',"Bloat statistics with pgstattuple: duration %.3f seconds.", $get_stat_time);
    } else {
      my $analyze_time = time;
      analyze($schema_name, $table_name);
      
      if ($DBI::err) {
        logger('quiet', "Table handling interrupt.");
        return -1;
      }

      $analyze_time = time - $analyze_time;
      logger('quiet', "Analyze required initial: duration %.3f second.", $analyze_time);
      $get_stat_time = time;
      $bloat_stats = get_bloat_stats($schema_name, $table_name);
      
      if ($DBI::err) {
        logger('quiet', "Table handling interrupt.");
        return -1;
      }

      $get_stat_time = time - $get_stat_time;
      if ($bloat_stats->{effective_page_count}) {
        logger('quiet', "Bloat statistics with pgstattuple: duration %.3f seconds.", $get_stat_time)
      } else {
        logger('qiuet', "Can not get bloat statistics, processing stopped.");
        $is_skipped = 1;  
      }
    }
  }
  if (!$is_locked && !$is_skipped) {
    my $can_be_compacted = ($bloat_stats->{'free_percent'} > 0 && ($stats->{page_count} > $bloat_stats->{effective_page_count}));
    if ($can_be_compacted) {
      logger('quiet', "Statistics: %d pages (%d pages including toasts and indexes) , approximately %0.3f%% (%d pages) can be compacted reducing the size by %s.",
        $stats->{page_count},
        $stats->{total_page_count},
        $bloat_stats->{'free_percent'},
        ($stats->{page_count} - $bloat_stats->{effective_page_count}),
        nice_size($bloat_stats->{free_space})
      );
    } else {
      logger('quiet', "Statistics: %d pages (%d pages including toasts and indexes)",
        $stats->{page_count},
        $stats->{total_page_count}
      );
    }

    if(has_triggers($schema_name, $table_name)) {
      
      if ($DBI::err) {
        logger('quiet', "Table handling interrupt.");
        return -1;
      }

      logger('quiet','Can not process: "always" or "replica" triggers are on.');
      $is_skipped = 1;
    }

    if(!$force) {      
      if($stats->{page_count} < MINIMAL_COMPACT_PAGES) {
        logger('quiet',"Skipping processing: %d pages from %d pages minimum required.'", $stats->{page_count}, MINIMAL_COMPACT_PAGES);
        $is_skipped = 1;
      }
      if(($bloat_stats->{free_percent}||0) <= MINIMAL_COMPACT_PERCENT) {
        logger('quiet',"Skipping processing: %0.2f%% space to compact from 20%% minimum required.",($bloat_stats->{free_percent}||0));
        $is_skipped = 1;  
      }
    }
  }

  my $is_compacted;
  
  if (!$is_locked && !$is_skipped) {
    logger('quiet', "Processing forced.") if ($force);
    my $vacuum_page_count = 0;
    my $initial_size_stats = {%$stats};
    my $to_page = $stats->{page_count} - 1;
    my $progress_report_time = time;
    my $clean_pages_total_duration = 0;
    my $last_loop = $stats->{page_count} + 1;
    my $expected_error_occurred = 0;

    my $expected_page_count = $stats->{page_count};
    my $column_name = get_update_column($schema_name, $table_name);

    if ($DBI::err) {
      logger('quiet', "Table handling interrupt.");
      return -1;
    }

    my $pages_per_round = get_pages_per_round($stats->{page_count}, $to_page);
    my $pages_before_vacuum = get_pages_before_vacuum($stats->{page_count}, $expected_page_count);

    my $max_tupples_per_page = get_max_tupples_per_page($schema_name, $table_name);

    if ($DBI::err) {
      logger('quiet', "Table handling interrupt.");
      return -1;
    }

    logger('quiet', "Update by column: %s.", $column_name||'');
    logger('quiet', "Set pages/round: %d.",  $pages_per_round);
    logger('quiet', "Set pages/vacuum: %d.", $pages_before_vacuum);

    my $start_time;
    my $last_to_page;
    my $loop;
    for ($loop = $stats->{page_count}; $loop > 0; $loop--) {
      $start_time = time;
      _dbh->begin_work;
      $last_to_page = $to_page;

      eval {
        $to_page = clean_pages($schema_name, $table_name, $column_name, $last_to_page, $pages_per_round,  $max_tupples_per_page); 
        $clean_pages_total_duration += (time - $start_time);
      };

      if ($@) {
        _dbh->rollback();

        if ($@ =~ 'deadlock detected') {
          logger('quiet',"Detected deadlock during cleaning.");
          next;
        } elsif ($@ =~ 'cannot extract system attribute') {
          logger('quiet', "System attribute extraction error has occurred, processing stopped.");
          $expected_error_occurred = 1;
          last;
        } else {
          logger('quiet',"Cannot handle table: %s",$@);
          return -1;
        }
      } else {
        if (defined $to_page) {
          # Normal cleaning completion
          if ($to_page == -1) {
            _dbh->rollback();
            $to_page = $last_to_page;
            last;
          }
        } else {
          # Bug trap warning
          logger('quiet', "Incorrect result of cleaning: column_name %s, to_page %d, pages_per_round %d, max_tupples_per_page %d.",$column_name, $last_to_page, $pages_per_round, $max_tupples_per_page);
        }
        _dbh->commit();
      } 

      sleep($delay_ratio * (time - $start_time));

      if (time - $progress_report_time >= PROGRESS_REPORT_PERIOD && $last_to_page != $to_page) {
        logger('quiet', "Progress: %s %d pages completed.", (defined $bloat_stats->{effective_page_count} ? int(100 * ($to_page ? ($initial_size_stats->{page_count} - $to_page - 1) / ($base_stats->{page_count} - $bloat_stats->{effective_page_count}) : 1) ).'%, ' : ' '), ($base_stats->{page_count} - $to_page - 1));
        $progress_report_time = time;
      }

      $expected_page_count -= $pages_per_round;
      $vacuum_page_count += ($last_to_page - $to_page);
      
      if ($routine_vacuum && $vacuum_page_count >= $pages_before_vacuum) {
        my $duration = $clean_pages_total_duration / ($last_loop - $loop);
        my $average_duration = $duration == 0 ? 0.0001 : $duration;
        logger('quiet', "Cleaning in average: %.1f pages/second (%.3f seconds per %d pages).", ($pages_per_round / $average_duration), $duration, $pages_per_round);
        $clean_pages_total_duration = 0;
        $last_loop = $loop;

        my $vacuum_time = time;
        vacuum($schema_name, $table_name);
        
        if ($DBI::err) {
          logger('quiet', "Table handling interrupt.");
          return -1;
        }

        $vacuum_time = time - $vacuum_time;

        $stats = get_size_stats($schema_name, $table_name);

        if ($DBI::err) {
         logger('quiet', "Table handling interrupt.");
          return -1;
        }

        if ($stats->{page_count} > $to_page + 1) {
          logger('quiet', "Vacuum routine: can not clean %d pages, %d pages left, duration %0.3f seconds.", ($stats->{page_count} - $to_page - 1), $stats->{page_count}, $vacuum_time);
        } else {
          logger('quiet', "Vacuum routine: %d pages left, duration %.3f seconds.", ($stats->{page_count}||0), $vacuum_time);
        }

        $vacuum_page_count = 0;

        my $last_pages_before_vacuum = $pages_before_vacuum;
        $pages_before_vacuum = get_pages_before_vacuum($stats->{page_count}, $expected_page_count); 
        if ($last_pages_before_vacuum != $pages_before_vacuum) {
          logger('quiet', "Set pages/vacuum: %d.", $pages_before_vacuum);
        }
      }

      if ($to_page >= $stats->{page_count}) {
        $to_page = $stats->{page_count} - 1;
      }

      if ($to_page <= 1) {
        $to_page = 0;
        last;
      }

      my $last_pages_per_round = $pages_per_round;
      $pages_per_round = get_pages_per_round($stats->{page_count}, $to_page);
        
      if ($last_pages_per_round != $pages_per_round) {
        logger('quiet', "Set pages/round: %d.",  $pages_per_round); 
      }
    }

    if ($loop == 0) {
      logger('quiet', "Maximum loops reached.");
    }

    if ($to_page > 0) {
      my $vacuum_time = time;
      sleep(1);
      vacuum($schema_name, $table_name);

      if ($DBI::err) {
        logger('quiet', "Table handling interrupt.");
        return -1;
      }

      $vacuum_time = time - $vacuum_time;

      $stats = get_size_stats($schema_name, $table_name);

      if ($DBI::err) {
        logger('quiet', "Table handling interrupt.");
        return -1;
      }
 
      if ($stats->{page_count} > $to_page + $pages_per_round) {
        logger('quiet', "Vacuum final: can not clean %d pages, %d pages left, duration %0.3f seconds.", ($stats->{page_count} - $to_page - $pages_per_round), $stats->{page_count}, $vacuum_time);
      } else {
        logger('quiet', "Vacuum final: %d pages left, duration %.3f seconds.", ($stats->{page_count}||0), $vacuum_time);
      }
    }

    #if (not $self->{'_no_final_analyze'}) {
    my $analyze_time = time;
    analyze($schema_name, $table_name);

    if ($DBI::err) {
      logger('quiet', "Table handling interrupt.");
      return -1;
    }

    $analyze_time = time - $analyze_time;
    logger('quiet', "Analyze final: duration %.3f second.", $analyze_time);
    #}

    my $get_stat_time = time;
    $bloat_stats = get_bloat_stats($schema_name, $table_name);
    
    if ($DBI::err) {
      logger('quiet', "Table handling interrupt.");
      return -1;
    }
    
    $get_stat_time = time - $get_stat_time;
    logger('quiet',"Bloat statistics with pgstattuple: duration %.3f seconds.", $get_stat_time);

    $pages_before_vacuum = get_pages_before_vacuum($stats->{page_count}, $expected_page_count);

    $is_compacted = (($stats->{page_count} <= $to_page + 1 + $pages_before_vacuum) && !$expected_error_occurred); 
  }

  my $will_be_skipped;
  
  $will_be_skipped = (!$force && ($is_skipped || $stats->{page_count} < MINIMAL_COMPACT_PAGES || $bloat_stats->{free_percent} < MINIMAL_COMPACT_PERCENT))  unless ($is_locked);
  
  my $is_reindexed;

  if (!$is_locked && ( $is_compacted || $attempt == $max_retry_count || $is_skipped || (!$is_skipped && $will_be_skipped)) && (!$no_reindex || $print_reindex_queries)) {
     
    my $index_data_list = get_index_data_list($schema_name, $table_name) || [];
    
    if ($DBI::err) {
      logger('quiet', "Table handling interrupt.");
      return -1;
    }

    for my $index_data (@$index_data_list) {
      my $initial_index_size_stats = get_index_size_statistics($schema_name, $index_data->{indexname});
      
      if (!$initial_index_size_stats || ref $initial_index_size_stats ne 'HASH') {
        logger('quiet', "Can not get index size statistics.");
        return;
      }
      
      if ($initial_index_size_stats->{page_count} <= 1) {
        logger('quiet', "Skipping reindex: %s.%s, empty or 1 page index.", $schema_name, $index_data->{indexname});
        next;
      }
      
      my $index_bloat_stats;
      if (! $force) {
        if ($index_data->{indmethod} ne 'btree') {
          logger('quiet', "Skipping reindex: %s.%s is a %s index not a btree, reindexing is up to you.", $schema_name, $index_data->{indexname}, $index_data->{indmethod}); 
          logger('quiet', "Reindex queries: %s.%s, initial size %d pages (%s)", $schema_name, $index_data->{indexname}, $initial_index_size_stats->{page_count}, nice_size($initial_index_size_stats->{size}));
          if ($index_data->{data}{allowed}) {
            logger('quiet', "%s; --%s", get_reindex_query($index_data), $db_name);
            logger('quiet', "%s; --%s", get_alter_index_query($schema_name, $table_name, $index_data), $db_name);
          } else {  
            logger('quiet', "%s; --%s", get_straight_reindex_query($schema_name, $table_name, $index_data), $db_name);
          }       
          next;
        }

        if ($initial_index_size_stats->{page_count} < MINIMAL_COMPACT_PAGES) {
          logger('quiet', "Skipping reindex: %s.%s, %d pages from %d pages minimum required.",$schema_name, $index_data->{indexname}, $initial_index_size_stats->{page_count}, MINIMAL_COMPACT_PAGES);
          next;
        }

        $index_bloat_stats = get_index_bloat_stats($schema_name, $index_data->{indexname});
         
        if ($index_bloat_stats && ref $index_bloat_stats eq 'HASH' && $index_bloat_stats->{'free_percent'} < MINIMAL_COMPACT_PERCENT) {
          logger('quiet', "Skipping reindex: %s.%s, %d%% space to compact from %d%% minimum required.", $schema_name, $index_data->{indexname}, $index_bloat_stats->{free_percent}, MINIMAL_COMPACT_PERCENT);
          next;
        }
      }

      if (not $index_data->{'allowed'}) {
        logger('quiet', "Skipping reindex: %s.%s, can not reindex without heavy locks because of its dependencies, reindexing is up to you.", $schema_name, $index_data->{indexname});
        logger('quiet', "Reindex queries%s: %s.%s, initial size %d pages (%s), will be reduced by %d%% (%s)",
           ($force ? ' forced' : ''),
           $schema_name, 
           $index_data->{indexname},
           $initial_index_size_stats->{page_count},
           nice_size($initial_index_size_stats->{size}),
           $index_bloat_stats->{free_percent},
           nice_size($index_bloat_stats->{free_space})
        );
        logger('quiet', "%s; --%s", get_reindex_query($index_data), $db_name);
        logger('quiet', "%s; --%s", get_alter_index_query($schema_name, $table_name, $index_data), $db_name);

        next;
      }

      if (!$no_reindex) {
        my $start_reindex_time = time;
        reindex($index_data);
        
        if($DBI::err) {
          logger('quiet', "Skipping index %s: %s", $index_data->{indexname});
          next;
        }

        my $reindex_time = time - $start_reindex_time;

        my $locked_alter_attempt = 0;
        while ($locked_alter_attempt < LOCKED_ALTER_COUNT) {
          eval {
            #print get_alter_index_query($schema_name, $table_name, $index_data);
            alter_index($schema_name, $table_name, $index_data);
            $reindex_time = time - $start_reindex_time;
          };
          if ($@) {
            if ($@ =~ ('canceling statement due '.
                   'to statement timeout'))
            { 
              $locked_alter_attempt++;
              next;
            } else {
              logger('quiet', $@);
              return;
            }
          } else {
            last;
          }
        }
        if ($locked_alter_attempt < LOCKED_ALTER_COUNT) {
            my $new_stats = get_index_size_statistics($schema_name, $index_data->{indexname});
            my $free_percent = 100 * (1 - $new_stats->{size} / $initial_index_size_stats->{size});
            my $free_space = ($initial_index_size_stats->{size} - $new_stats->{size});
            logger('quiet', "Reindex%s: %s.%s, initial size %d pages(%s), has been reduced by %d%% (%s), duration %d seconds, attempts %d.",
              ($force ? " forced" : ""),
              $schema_name,
              $index_data->{indexname},
              $initial_index_size_stats->{page_count},
              nice_size($initial_index_size_stats->{size}),
              int($free_percent),
              nice_size($free_space),
              $reindex_time,
              $locked_alter_attempt
            );
                
          $is_reindexed = (defined $is_reindexed) ? ($is_reindexed and 1) : 1;
        } else {
          my $drop_index_time = time;
          drop_temp_index($schema_name);
          $reindex_time += time - $drop_index_time;
          logger('quiet', "Reindex%s: %s.%s, lock has not been acquired, initial size %d pages(%d), , can be reduced by %d%% (%s), duration %d seconds.",
            ($force ? " forced" : ""),
            $schema_name,
            $index_data->{indexname},
            $initial_index_size_stats->{page_count},
            nice_size($initial_index_size_stats->{size}),
            $bloat_stats->{free_percent},
            nice_size($bloat_stats->{free_space}),
            $reindex_time
          );  
          $is_reindexed = 0;
        }
      }

      if ($print_reindex_queries) {
        logger('quiet', "Reindex queries%s: %s.%s, initial size %d pages (%s), will be reduced by %d%% (%s)",
           ($force ? ' forced' : ''),
           $schema_name,
           $index_data->{indexname},
           $initial_index_size_stats->{page_count},
           nice_size($initial_index_size_stats->{size}),
           $index_bloat_stats->{free_percent},
           nice_size($index_bloat_stats->{free_space})
        );
        logger('quiet', "%s; --%s", get_reindex_query($index_data), $db_name);
        logger('quiet', "%s; --%s", get_alter_index_query($schema_name, $table_name, $index_data), $db_name);
      }
    }      
    
    if (!$no_reindex) {
      $stats = get_size_stats($schema_name, $table_name);
    
      if ($DBI::err) {
        logger('quiet', "Table handling interrupt.");
        return -1;
      }
    }
  }
    
  if (!$is_locked && !($is_skipped && !defined($is_reindexed))) {
    my $complete = (($is_compacted || $will_be_skipped || $is_skipped) && (defined $is_reindexed ? $is_reindexed : 1));
    if ($complete) {
      logger('quiet', "Processing complete.");
    } else {
      logger('quiet', "Processing incomplete.");
    }

    if (defined $bloat_stats->{free_percent} && defined $bloat_stats->{effective_page_count} && $bloat_stats->{free_percent} > 0 && $stats->{page_count} > $bloat_stats->{effective_page_count} && !$complete) {
      logger('quiet', "Processing results: %d pages left (%d pages including toasts and indexes), size reduced by %s (%s including toasts and indexes) in total , approximately %d%% (%d pages) that is %s more were expected to be compacted after this attempt.",
        $stats->{page_count},
        $stats->{total_page_count},
        nice_size($base_stats->{size}),
        nice_size($base_stats->{total_size}),
        $bloat_stats->{free_percent},
        $stats->{page_count} - $bloat_stats->{effective_page_count},
        nice_size($bloat_stats->{free_space})
      );
    } else {
      logger('quiet', "Processing results: %d pages left (%d pages including toasts and indexes), size reduced by %s (%s including toasts and indexes) in total.",
        $stats->{page_count},
        $stats->{total_page_count},
        nice_size($base_stats->{size}),
        nice_size($base_stats->{total_size}),
      );
    }
  }

  return ($is_locked || ($is_compacted or $is_skipped or $will_be_skipped) and (defined $is_reindexed ? $is_reindexed : 1));
}

#Main code

help && exit(1) if $help;
man && exit(1) if $man;

my @dbs = ($db_name);

if($all_db) {
  $db_name = 'template1';
  unless(db_connect($db_name, $db_host, $db_port, $db_user, $db_passwd)) {
    logger('quiet', "Cannot get database list. Quit.");
    exit(0);
  }
  @dbs = 
  my $dbs = get_databases;
  unless ($dbs) {
    logger('quiet', "Interrupt processing");
    exit(0);
  }
  @dbs = @$dbs;

  db_disconnect;
}

if($exclude_schema) {
  %excluded_schemas = map {$_ => 1} split(/,/,$exclude_schema);
}

if($exclude_table) {
  %excluded_tables = map {$_ => 1} split(/,/,$exclude_table);
}


foreach my $current_db_name (@dbs) {
  $db_name = $current_db_name; 
  set_current_db_name($current_db_name);
  unset_current_schema_name_table_name;
  unless(db_connect($current_db_name, $db_host, $db_port, $db_user, $db_passwd)) {
    next;
  }

  set_session_replication_role;

  if ($DBI::err) {
    logger('quiet', "Database handling interrupt.");
    db_disconnect($current_db_name);
    next;
  }

  unless(get_pgstattuple_schema_name) {
    logger('qiuet', "Skip handling database %s: pgstattuple extention is not found", $current_db_name);
    db_disconnect($current_db_name);
    next;
  }

  unless (create_clean_pages_function) {
    logger('qiuet', "Skip handling database %s: pgstattuple cannot create clean_pages function", $current_db_name);
    db_disconnect($current_db_name);
    next;
  }

  my $database_tables = get_database_tables($current_db_name);
  unless($database_tables && ref $database_tables eq 'ARRAY') {
    logger('qiuet', "Skip handling database %s: cannot find tables", $current_db_name);
  }

  foreach my $current_ident (($schema_name && $table_name) ? ({schemaname => $schema_name, tablename => $table_name}) : @$database_tables) {
    next if (!$current_ident || ref $current_ident ne 'HASH' || $excluded_schemas{$current_ident->{schemaname}} || $excluded_tables{"$current_ident->{schemaname}.$current_ident->{tablename}"});
    set_current_schema_name_table_name($current_ident->{schemaname}, $current_ident->{tablename});
    logger('quiet', "Start handling table %s.%s", $current_ident->{schemaname}, $current_ident->{tablename});
    for (my $attempt = 0; $attempt < $max_retry_count; $attempt++) {
      last if process($current_ident->{schemaname}, $current_ident->{tablename}, $attempt);
    }
    logger('quiet', "Finish handling table %s.%s", $current_ident->{schemaname}, $current_ident->{tablename});
  }

  drop_clean_pages_function;
  
  db_disconnect($current_db_name);
}
1;
