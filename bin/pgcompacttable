#!/usr/bin/perl

use strict;
use warnings;

use POSIX;
use Getopt::Long;
use DBI;

use Data::Dumper;

my $option_hash;

select(STDOUT);

our $_log = select();
our $_log_level;
our $_dbh;

use constant MINIMAL_COMPACT_PAGES => 2;
use constant MINIMAL_COMPACT_PERCENT => 20;
use constant PAGES_PER_ROUND_DIVISOR => 1000;
use constant MAX_PAGES_PER_ROUND => 5;
use constant PAGES_BEFORE_VACUUM_LOWER_DIVISOR => 16;
use constant PAGES_BEFORE_VACUUM_LOWER_THRESHOLD => 1000;
use constant PAGES_BEFORE_VACUUM_UPPER_DIVISOR => 50;
use constant PROGRESS_REPORT_PERIOD => 60;

my $help;
my $man;

my $db_host = 'localhost';
my $db_port = 5432;
my $db_user = $ENV{LOGNAME} || $ENV{USER} || getpwuid($<);
my $db_passwd = '';

my $db_name = $ENV{LOGNAME} || $ENV{USER} || getpwuid($<);
my $schema_name = 'public';
my $table_name;

my $verbosity = 'notice';

my $force;

my $delay_ratio = 0;

my $routine_vacuum;
#logs

our %log_levels = (
  'quiet' => 0,
  'notice' => 1,
  'verbose' => 2
);

sub logger {
  my $level = shift;
  my $message = shift;
  my @message_args = @_;

  no strict;
  print $_log sprintf("$message\n", @message_args) if (($log_levels{$level} || 1) >= $_log_level);
  use strict;
}

sub help {
  logger('quiet', "This is help");
  return 1;
}

sub man {
  logger('quiet', "This is man");
  return 1;
}

sub nice_size
{
  my $size = shift;
  my @sizes=qw( B KB MB GB TB PB);

  my $i = 0;

  while ($size > 1024) {
    $size = $size / 1024;
    $i++;
  }
  return sprintf("%.3f$sizes[$i]", $size);
}

#DB procedures

sub _dbh {
  return $_dbh;
}

sub db_connect {
  my $db_name = shift;
  my $db_host = shift;
  my $db_port = shift;
  my $db_user = shift;
  my $db_password = shift;

  $_dbh = DBI->connect("DBI:Pg:dbname=$db_name;host=$db_host;port=$db_port", $db_user, $db_password,{RaiseError => 0, PrintError => 0, AutoCommit => 1});
  if($DBI::err) { die "Cannot connect to postgres: $DBI::errstr\n"; }

  return $_dbh;
}

sub get_ident_size {
  my $schema_name = shift;
  my $table_name = shift;
  
  my $ident_name = $schema_name.".".$table_name;
  my $sth = _dbh->prepare("
SELECT
    size,
    total_size,
    ceil(size::real / bs) AS page_count,
    ceil(total_size::real / bs) AS total_page_count
FROM (
    SELECT
        current_setting('block_size')::integer AS bs,
        pg_catalog.pg_relation_size(quote_ident(?)||'.'||quote_ident(?)) AS size,
        pg_catalog.pg_total_relation_size(quote_ident(?)||'.'||quote_ident(?)) AS total_size
) AS sq
");

  $sth->execute($schema_name, $table_name, $schema_name, $table_name);


  my $result = $sth->fetchrow_hashref;
  
  if (! $result || ref $result ne 'HASH') {
    die("Cannot get size statistics for table $ident_name.\n");
  }

  return $result;
}

sub get_bloat_stats {
  my $schema_name = shift;
  my $table_name = shift;

  my $ident_name = $schema_name.".".$table_name;
 
  my $sth = _dbh->prepare("
    SELECT nspname FROM pg_catalog.pg_proc
      JOIN pg_catalog.pg_namespace AS n ON pronamespace = n.oid
      WHERE proname = 'pgstattuple' LIMIT 1");
  $sth->execute();
  my ($pgstattuple_schema_name) = $sth->fetchrow_array;
 
  return undef unless($pgstattuple_schema_name);

  $sth = _dbh->prepare("SELECT
    ceil((size - free_space) * 100 / fillfactor / bs) AS effective_page_count,
    round(
        (100 * (1 - (100 - free_percent) / fillfactor))::numeric, 2
    ) AS free_percent,
    ceil(size - (size - free_space) * 100 / fillfactor) AS free_space
    FROM (
    SELECT
        current_setting('block_size')::integer AS bs,
        pg_catalog.pg_relation_size(pg_catalog.pg_class.oid) AS size,
        coalesce(
            (
                SELECT (
                    regexp_matches(
                        reloptions::text, E'.*fillfactor=(\\\\d+).*'))[1]),
            '100')::real AS fillfactor,
        pgst.*
    FROM pg_catalog.pg_class
    CROSS JOIN
        $pgstattuple_schema_name.pgstattuple(
            '$ident_name') AS pgst
    WHERE pg_catalog.pg_class.oid = '$ident_name'::regclass
    ) AS sq");
  $sth->execute;

 my $result = $sth->fetchrow_hashref;

 return $result;
}

sub get_update_column {
  my $schema_name = shift;
  my $table_name = shift;

  my $ident_name = $schema_name.".".$table_name;

  my $sth = _dbh->prepare("SELECT quote_ident(attname)
    FROM pg_catalog.pg_attribute
    WHERE
    attnum > 0 AND -- neither system
    NOT attisdropped AND -- nor dropped
    attrelid = '$ident_name'::regclass
    ORDER BY
    -- Variable legth attributes have lower priority because of the chance
    -- of being toasted
    (attlen = -1),
    -- Preferably not indexed attributes
    (
        attnum::text IN (
            SELECT regexp_split_to_table(indkey::text, ' ')
            FROM pg_catalog.pg_index
            WHERE indrelid = '$ident_name'::regclass)),
    -- Preferably smaller attributes
    attlen,
    attnum
    LIMIT 1;");

  $sth->execute;

  my ($result) = $sth->fetchrow_array;  
  return $result;
}

sub get_pages_per_round {
  my $page_count = shift;
  my $to_page = shift;

  my $real_pages_per_round = $page_count / PAGES_PER_ROUND_DIVISOR > 1 ? $page_count / PAGES_PER_ROUND_DIVISOR : 1; 
  my $pages_per_round = $real_pages_per_round < MAX_PAGES_PER_ROUND ? $real_pages_per_round : MAX_PAGES_PER_ROUND;
  my $result = ceil($pages_per_round) < $to_page ?  ceil($pages_per_round) : $to_page; 

  return $result;
}

sub get_pages_before_vacuum {
  my $page_count = shift;
  my $expected_page_count = shift;

  my $pages = $page_count / PAGES_BEFORE_VACUUM_LOWER_DIVISOR < PAGES_BEFORE_VACUUM_LOWER_THRESHOLD ? $page_count / PAGES_BEFORE_VACUUM_LOWER_DIVISOR : $page_count / PAGES_BEFORE_VACUUM_LOWER_THRESHOLD;
  my $result = $pages > $expected_page_count / PAGES_BEFORE_VACUUM_UPPER_DIVISOR ? $pages : $expected_page_count / PAGES_BEFORE_VACUUM_UPPER_DIVISOR;

  return ceil($result);
}

sub get_max_tupples_per_page {
  my $schema_name = shift;
  my $table_name = shift;

  my $ident_name = $schema_name.".".$table_name;

  my $sth = _dbh->prepare("
          SELECT ceil(current_setting('block_size')::real / sum(attlen))
          FROM pg_catalog.pg_attribute
          WHERE
              attrelid = '$ident_name'::regclass AND
              attnum < 0;
              ");
  $sth->execute;
  my ($result) = $sth->fetchrow_array; 

  die('Can not get max tupples per page.') unless(defined $result);

  return $result;
}

sub has_triggers {
  my $schema_name = shift;
  my $table_name = shift;

  my $ident_name = $schema_name.".".$table_name;

  my $sth = _dbh->prepare("SELECT count(1) FROM pg_catalog.pg_trigger
  WHERE
      tgrelid = '$ident_name'::regclass AND
      tgenabled IN ('A', 'R') AND
      (tgtype & 16)::boolean");
  $sth->execute;
  my ($result) = $sth->fetchrow_array;

  return $result;
}

sub try_advisory_lock {
  my $schema_name = shift;
  my $table_name = shift;
 
  my $sth = _dbh->prepare("
  SELECT pg_try_advisory_lock(
    'pg_catalog.pg_class'::regclass::integer,
    (quote_ident(?)||'.'||quote_ident(?))::regclass::integer)::integer;
    ");
  $sth->execute($schema_name, $table_name);
  my ($lock) = $sth->fetchrow_array;

  logger('notice', "Skipping processing: another instance is working with %s.%s", $schema_name, $table_name) unless ($lock); 
  
  return $lock;
}

sub vacuum {
  my $schema_name = shift;
  my $table_name = shift;
  my $analyze = shift; 
  

  my $sth = _dbh->do('VACUUM '.($analyze ? 'ANALYZE ' : '')."(quote_ident(?)||'.'||quote_ident(?)", undef, $schema_name, $table_name);

  return;
}

sub analyze {
  my $schema_name = shift;
  my $table_name = shift;

  my $sth = $_dbh->do('ANALYZE (quote_ident(?)||'.'||quote_ident(?)', undef, $schema_name, $table_name);
  
  return;
}

sub create_clean_pages_function {
  
  _dbh->do("
CREATE OR REPLACE FUNCTION public.pgcompact_clean_pages_$$(
    i_table_ident text,
    i_column_ident text,
    i_to_page integer,
    i_page_offset integer,
    i_max_tupples_per_page integer)
RETURNS integer
LANGUAGE plpgsql AS \$\$
DECLARE
    _from_page integer := i_to_page - i_page_offset + 1;
    _min_ctid tid;
    _max_ctid tid;
    _ctid_list tid[];
    _next_ctid_list tid[];
    _ctid tid;
    _loop integer;
    _result_page integer;
    _update_query text :=
        'UPDATE ONLY ' || i_table_ident ||
        ' SET ' || i_column_ident || ' = ' || i_column_ident ||
        ' WHERE ctid = ANY(\$1) RETURNING ctid';
BEGIN
    -- Check page argument values
    IF NOT (
        i_page_offset IS NOT NULL AND i_page_offset >= 1 AND
        i_to_page IS NOT NULL AND i_to_page >= 1 AND
        i_to_page >= i_page_offset)
    THEN
        RAISE EXCEPTION 'Wrong page arguments specified.';
    END IF;

    -- Check that session_replication_role is set to replica to
    -- prevent triggers firing
    IF NOT (
        SELECT setting = 'replica'
        FROM pg_catalog.pg_settings
        WHERE name = 'session_replication_role')
    THEN
        RAISE EXCEPTION 'The session_replication_role must be set to replica.';
    END IF;

    -- Define minimal and maximal ctid values of the range
    _min_ctid := (_from_page, 1)::text::tid;
    _max_ctid := (i_to_page, i_max_tupples_per_page)::text::tid;

    -- Build a list of possible ctid values of the range
    SELECT array_agg((pi, ti)::text::tid)
    INTO _ctid_list
    FROM generate_series(_from_page, i_to_page) AS pi
    CROSS JOIN generate_series(1, i_max_tupples_per_page) AS ti;

    <<_outer_loop>>
    FOR _loop IN 1..i_max_tupples_per_page LOOP
        _next_ctid_list := array[]::tid[];

        -- Update all the tuples in the range
        FOR _ctid IN EXECUTE _update_query USING _ctid_list
        LOOP
            IF _ctid > _max_ctid THEN
                _result_page := -1;
                EXIT _outer_loop;
            ELSIF _ctid >= _min_ctid THEN
                -- The tuple is still in the range, more updates are needed
                _next_ctid_list := _next_ctid_list || _ctid;
            END IF;
        END LOOP;

        _ctid_list := _next_ctid_list;

        -- Finish processing if there are no tupples in the range left
        IF coalesce(array_length(_ctid_list, 1), 0) = 0 THEN
            _result_page := _from_page - 1;
            EXIT _outer_loop;
        END IF;
    END LOOP;

    -- No result
    IF _loop = i_max_tupples_per_page AND _result_page IS NULL THEN
        RAISE EXCEPTION
            'Maximal loops count has been reached with no result.';
    END IF;

    RETURN _result_page;
END \$\$;
  ");

  return 1;
}

sub clean_pages {
  my $schema_name = shift;
  my $table_name = shift;
  my $column_name = shift;
  my $to_page = shift;
  my $pages_per_round = shift;
  my $max_tupples_per_page = shift;

  my $ident_name = $schema_name.".".$table_name;
  my $sth = _dbh->prepare("
    SELECT public.pgcompact_clean_pages_$$(?,?,?,?,?)
  ");
  warn "SELECT public.pgcompact_clean_pages_$$($ident_name, $column_name, $to_page,  $pages_per_round, $max_tupples_per_page)";
  $sth->execute($ident_name, $column_name, $to_page,  $pages_per_round, $max_tupples_per_page);
  
  my ($result) = $sth->fetchrow_array;

warn $result;

  return $result;
}

#Main code

GetOptions( 
            #help & man
            'help|?' => \$help,
            'm|man' => \$man,

            #database connection parameters
            'h|host=s' => \$db_host,
            'p|port=i' => \$db_port,
            'U|user=s' => \$db_user,
            'W|password=s' => \$db_passwd,
            'd=s' => \$db_name,
            'n|schema=s' => \$schema_name,
            't|table=s' => \$table_name,
            'v|verbosity=s' => \$verbosity,
            'f|force' => \$force,
            #'delay-ratio=i' => \$delay_ratio,
            #'routine_vacuum' => $routine_vacuum,
          );

$_log_level = $log_levels{$verbosity} || 1; 

help && exit(1) if $help;
man && exit(1) if $man;

die "Cannot run without table name\n" unless ($table_name);

db_connect($db_name, $db_host, $db_port, $db_user, $db_passwd);

create_clean_pages_function;

my $stats = get_ident_size($schema_name, $table_name); 

my $locked = try_advisory_lock($schema_name, $table_name);

my $base_stats;
$base_stats = $stats unless ($base_stats);
my $skip;

if ($locked) {
  my $vacuum_time = time;
  vacuum($schema_name, $table_name);
  $vacuum_time = time - $vacuum_time;
  $stats = get_ident_size($schema_name, $table_name);

#  if ($stats->{page_count} > $stats->{page_count}) {
#    logger('quiet', "Vacuum initial: can not clean %d pages, %d' pages left, duration %d seconds.", ($stats->{page_count} - $stats->{page_count}), $stats->{page_count}, $vacuum_time);
#  } else {
    logger('quiet', "Vacuum initial: %d pages left, duration %.3f seconds.", ($stats->{page_count}||0), $vacuum_time);
#  }

  if($stats->{page_count} <= 1) {
    logger('quiet', "Skipping processing: empty or 1 page table.");
    die;
  }
}

if ($locked) {
  my $get_stat_time = time;
  my $bloat_stats = get_bloat_stats($schema_name, $table_name);
  $get_stat_time = time - $get_stat_time;
  if ($bloat_stats->{effective_page_count}) {
    logger('quiet',"Bloat statistics with pgstattuple: duration %.3f seconds.", $get_stat_time);
  } else {
    my $analyze_time = time;
    analyze($schema_name, $table_name);
    $analyze_time = time - $analyze_time;
    logger('quiet', "Analyze required initial: duration %.3f second.", $analyze_time);
    $get_stat_time = time;
    $bloat_stats = get_bloat_stats($schema_name, $table_name);
    $get_stat_time = time - $get_stat_time;
    if ($bloat_stats->{effective_page_count}) {
      logger('quiet',"message => ('Bloat statistics with pgstattuple: duration %.3f seconds.", $get_stat_time)
    } else {
      die "Can not get bloat statistics, processing stopped.";
    }
  }
  
  my $can_be_compacted = ($bloat_stats->{'free_percent'} > 0 && ($stats->{page_count} > $bloat_stats->{effective_page_count}));
  if ($can_be_compacted) {
    logger('quiet', "Statistics: %d pages (%d pages including toasts and indexes) , approximately %0.3f%% (%d pages) can be compacted reducing the size by %s.",
      $stats->{page_count},
      $stats->{total_page_count},
      $bloat_stats->{'free_percent'},
      ($stats->{page_count} > $bloat_stats->{effective_page_count}),
      nice_size($bloat_stats->{free_space})
    );
  } else {
    logger('quiet', "Statistics: %d pages (%d pages including toasts and indexes)",
      $stats->{page_count},
      $stats->{total_page_count}
    );
  }

  if(has_triggers($schema_name, $table_name)) {
    logger('quiet','Can not process: "always" or "replica" triggers are on.');
    die;
  }

  if(!$force) {      
    if($stats->{page_count} < MINIMAL_COMPACT_PAGES) {
      logger('quiet',"Skipping processing: %d pages from 2 pages minimum required.'", $stats->{page_count});
      die;
    }
    if(($bloat_stats->{free_percent}||0) <= MINIMAL_COMPACT_PERCENT) {
      logger('quiet',"Skipping processing: %d%% space to compact from 20%% minimum required.",($bloat_stats->{free_percent}||0));
      die Dumper $stats;
    }
    logger('quiet', "Processing forced.");
  }

  my $is_compacted;

  my $vacuum_page_count = 0;
  my $initial_size_statistics = %$stats;
  my $to_page = $stats->{page_count} - 1;
  my $progress_report_time = time;
  my $clean_pages_total_duration = 0;
  my $last_loop = $stats->{page_count} + 1;
  my $expected_error_occurred = 0;

  my $expected_page_count = $stats->{page_count};
  my $column_name = get_update_column($schema_name, $table_name);

  my $pages_per_round = get_pages_per_round($stats->{page_count}, $to_page);
  my $pages_before_vacuum = get_pages_before_vacuum($stats->{page_count}, $expected_page_count);

  my $max_tupples_per_page = get_max_tupples_per_page($schema_name, $table_name);

  logger('quiet', "Update by column: %s.", $column_name||'');
  logger('quiet', "Set pages/round: %d.",  $pages_per_round);
  logger('quiet', "Set pages/vacuum: %d.", $pages_before_vacuum);

  my $start_time;
  my $last_to_page;
  my $loop;
  for($loop = $stats->{page_count}; $loop > 0; $loop--) {
    $start_time = time;
    _dbh->begin_work;
    $last_to_page = $to_page;

    eval {
      $to_page = clean_pages($schema_name, $table_name, $column_name, $last_to_page, $pages_per_round,  $max_tupples_per_page); 
      $clean_pages_total_duration += (time - $start_time);
    };

    if ($@) {
      _dbh->rollback();

      if ($@ =~ 'deadlock detected') {
        logger('quiet',"Detected deadlock during cleaning.");
        next;
      } elsif ($@ =~ 'cannot extract system attribute') {
        logger('quiet', "System attribute extraction error has occurred, processing stopped.");
        $expected_error_occurred = 1;
        last;
      } else {
        die($@);
      }
    } else {
      if (defined $to_page) {
        # Normal cleaning completion
        if ($to_page == -1) {
          _dbh->rollback();
          $to_page = $last_to_page;
          last;
        }
      } else {
        # Bug trap warning
        logger('quiet', "Incorrect result of cleaning: column_name %s, to_page %d, pages_per_round %d, max_tupples_per_page %d.",$column_name, $last_to_page, $pages_per_round, $max_tupples_per_page);
      }

      _dbh->commit();
    } 

    sleep($delay_ratio * (time - $start_time));

    if (time - $progress_report_time >= PROGRESS_REPORT_PERIOD && $last_to_page != $to_page) {
      logger('quiet', "Progress: %s %d pages completed.", (defined $bloat_stats->{effective_page_count} ? int(100 * ($to_page ? ($base_stats->{page_count} - $to_page - 1) / ($base_stats->{page_count} - $bloat_stats->{effective_page_count}) : 1) ).'%, ' : ' '), ($base_stats->{page_count} - $to_page - 1));
      $progress_report_time = time;
    }

    $expected_page_count -= $pages_per_round;
    $vacuum_page_count += ($last_to_page - $to_page);

    if ($routine_vacuum && $vacuum_page_count >= $pages_before_vacuum) {
      my $duration = $clean_pages_total_duration / ($last_loop - $loop);
      my $average_duration = $duration == 0 ? 0.0001 : $duration;
      logger('quiet', "Cleaning in average: %.1f pages/second (%.3f seconds per %d pages).", ($pages_per_round / $average_duration), $duration, $pages_per_round);
      $clean_pages_total_duration = 0;
      $last_loop = $loop;

      my $vacuum_time = time;
      vacuum($schema_name, $table_name);
      $vacuum_time = time - $vacuum_time;

      $stats = get_ident_size($schema_name, $table_name);

      if ($stats->{page_count} > $to_page + 1) {
        logger('quiet', "Vacuum routine: can not clean %d pages, %d' pages left, duration %d seconds.", ($stats->{page_count} - $to_page - 1), $stats->{page_count}, $vacuum_time);
      } else {
        logger('quiet', "Vacuum routine: %d pages left, duration %.3f seconds.", ($stats->{page_count}||0), $vacuum_time);
      }

      $vacuum_page_count = 0;

      my $last_pages_before_vacuum = $pages_before_vacuum;
      $pages_before_vacuum = get_pages_before_vacuum($stats->{page_count}, $expected_page_count); 
      if ($last_pages_before_vacuum != $pages_before_vacuum) {
        logger('quiet', "Set pages/vacuum: %d.", $pages_before_vacuum);
      }
    }

    if ($to_page >= $stats->{page_count}) {
      $to_page = $stats->{page_count} - 1;
    }

    if ($to_page <= 1) {
      $to_page = 0;
      last;
    }

    my $last_pages_per_round = $pages_per_round;
    $pages_per_round = get_pages_per_round($stats->{page_count}, $to_page);
      
    if ($last_pages_per_round != $pages_per_round) {
      logger('quiet', "Set pages/round: %d.",  $pages_per_round); 
    }
  }

  if ($loop == 0) {
    logger('quiet', "Maximum loops reached.");
  }

  if ($to_page > 0) {
    my $vacuum_time = time;
    vacuum($schema_name, $table_name);
    $vacuum_time = time - $vacuum_time;

    $stats = get_ident_size($schema_name, $table_name);;
    
    if ($stats->{page_count} > $to_page + $pages_per_round) {
      logger('quiet', "Vacuum final: can not clean %d pages, %d' pages left, duration %d seconds.", ($stats->{page_count} - $to_page - $pages_per_round), $stats->{page_count}, $vacuum_time);
    } else {
      logger('quiet', "Vacuum final: %d pages left, duration %.3f seconds.", ($stats->{page_count}||0), $vacuum_time);
    }
  }

  #if (not $self->{'_no_final_analyze'}) {
  my $analyze_time = time;
  analyze($schema_name, $table_name);
  $analyze_time = time - $analyze_time;
  logger('quiet', "Analyze final: duration %.3f second.", $analyze_time);
  #}

  $get_stat_time = time;
  $bloat_stats = get_bloat_stats($schema_name, $table_name);
  $get_stat_time = time - $get_stat_time;
  logger('quiet',"Bloat statistics with pgstattuple: duration %.3f seconds.", $get_stat_time);

  $pages_before_vacuum = get_pages_before_vacuum($stats->{page_count}, $expected_page_count);

  $is_compacted = (($stats->{page_count} <= $to_page + 1 + $pages_before_vacuum) && !$expected_error_occurred); 
}

print "Alles\n";

1;
