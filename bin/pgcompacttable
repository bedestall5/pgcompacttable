#!/usr/bin/perl

use strict;
use warnings;

use POSIX;
use Getopt::Long;
use DBI;

use Data::Dumper;

my $option_hash;

select(STDOUT);

our $_log = select();
our $_log_level;
our $_dbh;

use constant MINIMAL_COMPACT_PAGES => 2;
use constant MINIMAL_COMPACT_PERCENT => 20;
use constant PAGES_PER_ROUND_DIVISOR => 1000;
use constant MAX_PAGES_PER_ROUND => 5;
use constant PAGES_BEFORE_VACUUM_LOWER_DIVISOR => 16;
use constant PAGES_BEFORE_VACUUM_LOWER_THRESHOLD => 1000;
use constant PAGES_BEFORE_VACUUM_UPPER_DIVISOR => 50;

my $help;
my $man;

my $db_host = 'localhost';
my $db_port = 5432;
my $db_user = $ENV{LOGNAME} || $ENV{USER} || getpwuid($<);
my $db_passwd = '';

my $db_name = $ENV{LOGNAME} || $ENV{USER} || getpwuid($<);
my $schema_name = 'public';
my $table_name;

my $verbosity = 'notice';

my $force;

#logs

our %log_levels = (
  'quiet' => 0,
  'notice' => 1,
  'verbose' => 2
);

sub logger {
  my $level = shift;
  my $message = shift;
  my @message_args = @_;

  no strict;
  print $_log sprintf("$message\n", @message_args) if (($log_levels{$level} || 1) >= $_log_level);
  use strict;
}

sub help {
  logger('quiet', "This is help");
  return 1;
}

sub man {
  logger('quiet', "This is man");
  return 1;
}

sub nice_size
{
  my $size = shift;
  my @sizes=qw( B KB MB GB TB PB);

  my $i = 0;

  while ($size > 1024) {
    $size = $size / 1024;
    $i++;
  }
  return sprintf("%.3f$sizes[$i]", $size);
}

#DB procedures

sub _dbh {
  return $_dbh;
}

sub db_connect {
  my $db_name = shift;
  my $db_host = shift;
  my $db_port = shift;
  my $db_user = shift;
  my $db_password = shift;

  $_dbh = DBI->connect("DBI:Pg:dbname=$db_name;host=$db_host;port=$db_port", $db_user, $db_password,{RaiseError => 0, PrintError => 0, AutoCommit => 1});
  if($DBI::err) { die "Cannot connect to postgres: $DBI::errstr\n"; }

  return $_dbh;
}

sub get_ident_size {
  my $schema_name = shift;
  my $table_name = shift;
  
  my $ident_name = $schema_name.".".$table_name;
  my $sth = _dbh->prepare("
SELECT
    size,
    total_size,
    ceil(size::real / bs) AS page_count,
    ceil(total_size::real / bs) AS total_page_count
FROM (
    SELECT
        current_setting('block_size')::integer AS bs,
        pg_catalog.pg_relation_size(quote_ident(?)||'.'||quote_ident(?)) AS size,
        pg_catalog.pg_total_relation_size(quote_ident(?)||'.'||quote_ident(?)) AS total_size
) AS sq
");

  $sth->execute($schema_name, $table_name, $schema_name, $table_name);


  my $result = $sth->fetchrow_hashref;
  
  if (! $result || ref $result ne 'HASH') {
    die("Cannot get size statistics for table $ident_name.\n");
  }

  return $result;
}

sub get_bloat_stats {
  my $schema_name = shift;
  my $table_name = shift;

  my $ident_name = $schema_name.".".$table_name;
 
  my $sth = _dbh->prepare("
    SELECT nspname FROM pg_catalog.pg_proc
      JOIN pg_catalog.pg_namespace AS n ON pronamespace = n.oid
      WHERE proname = 'pgstattuple' LIMIT 1");
  $sth->execute();
  my ($pgstattuple_schema_name) = $sth->fetchrow_array;
 
  return undef unless($pgstattuple_schema_name);

  $sth = _dbh->prepare("SELECT
    ceil((size - free_space) * 100 / fillfactor / bs) AS effective_page_count,
    round(
        (100 * (1 - (100 - free_percent) / fillfactor))::numeric, 2
    ) AS free_percent,
    ceil(size - (size - free_space) * 100 / fillfactor) AS free_space
    FROM (
    SELECT
        current_setting('block_size')::integer AS bs,
        pg_catalog.pg_relation_size(pg_catalog.pg_class.oid) AS size,
        coalesce(
            (
                SELECT (
                    regexp_matches(
                        reloptions::text, E'.*fillfactor=(\\\\d+).*'))[1]),
            '100')::real AS fillfactor,
        pgst.*
    FROM pg_catalog.pg_class
    CROSS JOIN
        $pgstattuple_schema_name.pgstattuple(
            '$ident_name') AS pgst
    WHERE pg_catalog.pg_class.oid = '$ident_name'::regclass
    ) AS sq");
  $sth->execute;

 my $result = $sth->fetchrow_hashref;

 return $result;
}

sub get_update_column {
  my $schema_name = shift;
  my $table_name = shift;

  my $ident_name = $schema_name.".".$table_name;

  my $sth = _dbh->prepare("SELECT quote_ident(attname)
    FROM pg_catalog.pg_attribute
    WHERE
    attnum > 0 AND -- neither system
    NOT attisdropped AND -- nor dropped
    attrelid = '$ident_name'::regclass
    ORDER BY
    -- Variable legth attributes have lower priority because of the chance
    -- of being toasted
    (attlen = -1),
    -- Preferably not indexed attributes
    (
        attnum::text IN (
            SELECT regexp_split_to_table(indkey::text, ' ')
            FROM pg_catalog.pg_index
            WHERE indrelid = '$ident_name'::regclass)),
    -- Preferably smaller attributes
    attlen,
    attnum
    LIMIT 1;");

  $sth->execute;

  my ($result) = $sth->fetchrow_array;  
  return $result;
}

sub get_pages_per_round {
  my $page_count = shift;
  my $to_page = shift;

  my $real_pages_per_round = $page_count / PAGES_PER_ROUND_DIVISOR > 1 ? $page_count / PAGES_PER_ROUND_DIVISOR : 1; 
  my $pages_per_round = $real_pages_per_round < MAX_PAGES_PER_ROUND ? $real_pages_per_round : MAX_PAGES_PER_ROUND;
  my $result = ceil($pages_per_round) < $to_page ?  ceil($pages_per_round) : $to_page; 

  return $result;
}

sub get_pages_before_vacuum {
  my $page_count = shift;
  my $expected_page_count = shift;

  my $pages = $page_count / PAGES_BEFORE_VACUUM_LOWER_DIVISOR < PAGES_BEFORE_VACUUM_LOWER_THRESHOLD ? $page_count / PAGES_BEFORE_VACUUM_LOWER_DIVISOR : $page_count / PAGES_BEFORE_VACUUM_LOWER_THRESHOLD;
  my $result = $pages > $expected_page_count / PAGES_BEFORE_VACUUM_UPPER_DIVISOR ? $pages : $expected_page_count / PAGES_BEFORE_VACUUM_UPPER_DIVISOR;

  return ceil($result);
}

sub get_max_tupples_per_page {
  my $schema_name = shift;
  my $table_name = shift;

  my $ident_name = $schema_name.".".$table_name;

  my $sth = _dbh->prepare("
          SELECT ceil(current_setting('block_size')::real / sum(attlen))
          FROM pg_catalog.pg_attribute
          WHERE
              attrelid = '$ident_name'::regclass AND
              attnum < 0;
              ");
  $sth->execute;
  my ($result) = $sth->fetchrow_array; 

  die('Can not get max tupples per page.') unless(defined $result);

  return $result;
}

sub has_triggers {
  my $schema_name = shift;
  my $table_name = shift;

  my $ident_name = $schema_name.".".$table_name;

  my $sth = _dbh->prepare("SELECT count(1) FROM pg_catalog.pg_trigger
  WHERE
      tgrelid = '$ident_name'::regclass AND
      tgenabled IN ('A', 'R') AND
      (tgtype & 16)::boolean");
  $sth->execute;
  my ($result) = $sth->fetchrow_array;

  return $result;
}

sub try_advisory_lock {
  my $schema_name = shift;
  my $table_name = shift;
 
  my $sth = _dbh->prepare("
  SELECT pg_try_advisory_lock(
    'pg_catalog.pg_class'::regclass::integer,
    (quote_ident(?)||'.'||quote_ident(?))::regclass::integer)::integer;
    ");
  $sth->execute($schema_name, $table_name);
  my ($lock) = $sth->fetchrow_array;

  logger('notice', "Skipping processing: another instance is working with %s.%s", $schema_name, $table_name) unless ($lock); 
  
  return $lock;
}

sub vacuum {
  my $schema_name = shift;
  my $table_name = shift;
  my $analyze = shift; 
  

  my $sth = _dbh->do('VACUUM '.($analyze ? 'ANALYZE ' : '')."(quote_ident(?)||'.'||quote_ident(?)", undef, $schema_name, $table_name);

  return;
}

sub analyze {
  my $schema_name = shift;
  my $table_name = shift;

  my $sth = $_dbh->do('ANALYZE (quote_ident(?)||'.'||quote_ident(?)', undef, $schema_name, $table_name);
  
  return;
}

#Main code

GetOptions( 
            #help & man
            'help|?' => \$help,
            'm|man' => \$man,

            #database connection parameters
            'h|host=s' => \$db_host,
            'p|port=i' => \$db_port,
            'U|user=s' => \$db_user,
            'W|password=s' => \$db_passwd,
            'd=s' => \$db_name,
            'n|schema=s' => \$schema_name,
            't|table=s' => \$table_name,
            'v|verbosity=s' => \$verbosity,
            'f|force' => \$force,
          );

$_log_level = $log_levels{$verbosity} || 1; 

help && exit(1) if $help;
man && exit(1) if $man;

die "Cannot run without table name\n" unless ($table_name);

db_connect($db_name, $db_host, $db_port, $db_user, $db_passwd);

my $stats = get_ident_size($schema_name, $table_name); 

my $locked = try_advisory_lock($schema_name, $table_name);

my $base_stats;
$base_stats = $stats unless ($base_stats);
my $skip;

if ($locked) {
  my $vacuum_time = time;
  vacuum($schema_name, $table_name);
  $vacuum_time = time - $vacuum_time;
  $stats = get_ident_size($schema_name, $table_name);

  logger('quiet', "Vacuum initial: %d pages left, duration %.3f seconds.", ($stats->{page_count}||0), $vacuum_time);

  if($stats->{page_count} <= 1) {
    logger('quiet', "Skipping processing: empty or 1 page table.");
    die;
  }
}

if ($locked) {
  my $get_stat_time = time;
  my $bloat_stats = get_bloat_stats($schema_name, $table_name);
  $get_stat_time = time - $get_stat_time;
  if ($bloat_stats->{effective_page_count}) {
    logger('quiet',"Bloat statistics with pgstattuple: duration %.3f seconds.", $get_stat_time)
  } else {
    my $analyze_time = time;
    analyze($schema_name, $table_name);
    $analyze_time = time - $analyze_time;
    logger('quiet', "Analyze required initial: duration %.3f second.", $analyze_time);
    $get_stat_time = time;
    $bloat_stats = get_bloat_stats($schema_name, $table_name);
    $get_stat_time = time - $get_stat_time;
    if ($bloat_stats->{effective_page_count}) {
      logger('quiet',"message => ('Bloat statistics with pgstattuple: duration %.3f seconds.", $get_stat_time)
    } else {
      die "Can not get bloat statistics, processing stopped.";
    }
  }
  
  my $can_be_compacted = ($bloat_stats->{'free_percent'} > 0 && ($stats->{page_count} > $bloat_stats->{effective_page_count}));
  if ($can_be_compacted) {
    logger('quiet', "Statistics: %d pages (%d pages including toasts and indexes) , approximately %0.3f%% (%d pages) can be compacted reducing the size by %s.",
      $stats->{page_count},
      $stats->{total_page_count},
      $bloat_stats->{'free_percent'},
      ($stats->{page_count} > $bloat_stats->{effective_page_count}),
      nice_size($bloat_stats->{free_space})
    );
  } else {
    logger('quiet', "Statistics: %d pages (%d pages including toasts and indexes)",
      $stats->{page_count},
      $stats->{total_page_count}
    );
  }

  if(has_triggers($schema_name, $table_name)) {
    logger('quiet','Can not process: "always" or "replica" triggers are on.');
    die;
  }

  if(!$force) {      
    if($stats->{page_count} < MINIMAL_COMPACT_PAGES) {
      logger('quiet',"Skipping processing: %d pages from 2 pages minimum required.'", $stats->{page_count});
      die;
    }
    if(($bloat_stats->{free_percent}||0) <= MINIMAL_COMPACT_PERCENT) {
      logger('quiet',"Skipping processing: %d%% space to compact from 20%% minimum required.",($bloat_stats->{free_percent}||0));
      die Dumper $stats;
    }
    logger('quiet', "Processing forced.");
  }

  my $vacuum_page_count = 0;
  my $initial_size_statistics = %$stats;
  my $to_page = $stats->{page_count} - 1;
  my $progress_report_time = time;
  my $clean_pages_total_duration = 0;
  my $last_loop = $stats->{page_count} + 1;
  my $expected_error_occurred = 0;

  my $expected_page_count = $stats->{page_count};
  my $column_ident = get_update_column($schema_name, $table_name);

  my $pages_per_round = get_pages_per_round($stats->{page_count}, $to_page);
  my $pages_before_vacuum = get_pages_before_vacuum($stats->{page_count}, $expected_page_count);

  my $max_tupples_per_page = get_max_tupples_per_page($schema_name, $table_name);

  logger('quiet', "Update by column: %s.", $column_ident||'');
  logger('quiet', "Set pages/round: %d.",  $pages_per_round);
  logger('quiet', "Set pages/vacuum: %d.", $pages_before_vacuum);
  
}

print "Alles\n";

1;
